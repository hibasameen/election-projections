{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d13b5125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/hibasameen/anaconda3/envs/uk-polls/lib/python3.11/site-packages (2.32.5)\n",
      "Requirement already satisfied: pandas in /Users/hibasameen/anaconda3/envs/uk-polls/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/hibasameen/anaconda3/envs/uk-polls/lib/python3.11/site-packages (4.14.2)\n",
      "Requirement already satisfied: lxml in /Users/hibasameen/anaconda3/envs/uk-polls/lib/python3.11/site-packages (4.9.4)\n",
      "Collecting flask\n",
      "  Downloading flask-3.1.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/hibasameen/anaconda3/envs/uk-polls/lib/python3.11/site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/hibasameen/anaconda3/envs/uk-polls/lib/python3.11/site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/hibasameen/anaconda3/envs/uk-polls/lib/python3.11/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hibasameen/anaconda3/envs/uk-polls/lib/python3.11/site-packages (from requests) (2025.10.5)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/hibasameen/anaconda3/envs/uk-polls/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/hibasameen/anaconda3/envs/uk-polls/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/hibasameen/anaconda3/envs/uk-polls/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/hibasameen/anaconda3/envs/uk-polls/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/hibasameen/anaconda3/envs/uk-polls/lib/python3.11/site-packages (from beautifulsoup4) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/hibasameen/anaconda3/envs/uk-polls/lib/python3.11/site-packages (from beautifulsoup4) (4.15.0)\n",
      "Collecting blinker>=1.9.0 (from flask)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting click>=8.1.3 (from flask)\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting itsdangerous>=2.2.0 (from flask)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in /Users/hibasameen/anaconda3/envs/uk-polls/lib/python3.11/site-packages (from flask) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /Users/hibasameen/anaconda3/envs/uk-polls/lib/python3.11/site-packages (from flask) (3.0.3)\n",
      "Collecting werkzeug>=3.1.0 (from flask)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/hibasameen/anaconda3/envs/uk-polls/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading flask-3.1.2-py3-none-any.whl (103 kB)\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Installing collected packages: werkzeug, itsdangerous, click, blinker, flask\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [flask]\n",
      "\u001b[1A\u001b[2KSuccessfully installed blinker-1.9.0 click-8.3.0 flask-3.1.2 itsdangerous-2.2.0 werkzeug-3.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests pandas beautifulsoup4 lxml flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed9b3940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: uk_polling_2025_national_dates_for_chart.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wm/rntml9cj7270lh5ry0v4gjhc0000gn/T/ipykernel_20785/1058893380.py:37: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(table_html, header=[0,1])[0]\n"
     ]
    }
   ],
   "source": [
    "# pip install requests pandas beautifulsoup4 lxml\n",
    "import re\n",
    "from datetime import date, timedelta\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "WIKI_PAGE = \"Opinion_polling_for_the_next_United_Kingdom_general_election\"\n",
    "HEADERS = {\"User-Agent\":\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119 Safari/537.36\"}\n",
    "DEFAULT_YEAR = 2025\n",
    "RAW_OUT  = Path(\"uk_polling_2025_national.csv\")\n",
    "CLEAN_OUT = Path(\"uk_polling_2025_national_dates_for_chart.csv\")\n",
    "\n",
    "def fetch_html():\n",
    "    for url in [\n",
    "        f\"https://en.wikipedia.org/api/rest_v1/page/html/{WIKI_PAGE}\",\n",
    "        f\"https://en.wikipedia.org/w/index.php?title={WIKI_PAGE}&printable=yes\",\n",
    "        f\"https://en.wikipedia.org/wiki/{WIKI_PAGE}\",\n",
    "    ]:\n",
    "        r = requests.get(url, headers=HEADERS, timeout=30)\n",
    "        if r.ok: return r.text\n",
    "    raise RuntimeError(\"Could not fetch Wikipedia page.\")\n",
    "\n",
    "def extract_2025_table_html(html):\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    h = soup.find(lambda t: t.name in (\"h2\",\"h3\") and (t.get(\"id\")==\"2025\" or t.get_text(strip=True)==\"2025\"))\n",
    "    if not h: raise RuntimeError(\"2025 heading not found.\")\n",
    "    nxt = h.find_next()\n",
    "    while nxt and not (nxt.name==\"table\" and \"wikitable\" in (nxt.get(\"class\") or [])):\n",
    "        nxt = nxt.find_next()\n",
    "    if not nxt: raise RuntimeError(\"2025 wikitable not found.\")\n",
    "    return str(nxt)\n",
    "\n",
    "def table_to_df(table_html):\n",
    "    try:\n",
    "        df = pd.read_html(table_html, header=[0,1])[0]\n",
    "        df.columns = [c[0] for c in df.columns]\n",
    "    except Exception:\n",
    "        df = pd.read_html(table_html, header=0)[0]\n",
    "    # drop duplicate header rows if any\n",
    "    header_like = tuple(df.columns.tolist())\n",
    "    mask = df.apply(lambda r: tuple(map(str, r.values)) == header_like, axis=1)\n",
    "    df = df.loc[~mask].copy()\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "    # order important columns if present\n",
    "    wanted = [\"Dates conducted\",\"Pollster\",\"Client\",\"Area\",\"Sample size\",\n",
    "              \"Lab\",\"Con\",\"Ref\",\"LD\",\"Grn\",\"SNP\",\"PC\",\"Others\",\"Lead\"]\n",
    "    cols = [c for c in wanted if c in df.columns] + [c for c in df.columns if c not in wanted]\n",
    "    return df[cols]\n",
    "\n",
    "# --- parse end of fieldwork to a single date ---\n",
    "MONTHS = {\"jan\":1,\"feb\":2,\"mar\":3,\"apr\":4,\"may\":5,\"jun\":6,\n",
    "          \"jul\":7,\"aug\":8,\"sep\":9,\"sept\":9,\"oct\":10,\"nov\":11,\"dec\":12}\n",
    "\n",
    "def to_end_of_fieldwork(s: str):\n",
    "    if pd.isna(s): return pd.NaT\n",
    "    t = str(s).replace(\"–\",\"-\").replace(\"—\",\"-\").replace(\"\\xa0\",\" \").strip()\n",
    "    # cases: \"26-27 Oct\", \"26 Sep - 3 Oct\", \"8 Oct\"\n",
    "    m = re.search(r\"(\\d{1,2})\\s+([A-Za-z]{3,})$\", t)\n",
    "    if not m: return pd.NaT\n",
    "    d, mon = m.groups()\n",
    "    mon = mon.lower()\n",
    "    mon = \"sept\" if mon.startswith(\"sept\") else mon[:3]\n",
    "    try:\n",
    "        return pd.Timestamp(year=DEFAULT_YEAR, month=MONTHS[mon], day=int(d))\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "def clean_pollster(s: str):\n",
    "    if pd.isna(s): return s\n",
    "    return re.sub(r\"\\s*\\[[^\\]]*\\]\", \"\", str(s)).strip()\n",
    "\n",
    "# ---- run ----\n",
    "html = fetch_html()\n",
    "tbl_html = extract_2025_table_html(html)\n",
    "df = table_to_df(tbl_html)\n",
    "df.to_csv(RAW_OUT, index=False)\n",
    "\n",
    "end = df[\"Dates conducted\"].apply(to_end_of_fieldwork)\n",
    "df[\"date\"] = end.dt.date\n",
    "df[\"year\"] = end.dt.year\n",
    "if \"Pollster\" in df.columns:\n",
    "    df[\"Pollster\"] = df[\"Pollster\"].apply(clean_pollster)\n",
    "\n",
    "front = [c for c in [\"date\",\"year\",\"Pollster\"] if c in df.columns]\n",
    "rest = [c for c in df.columns if c not in front]\n",
    "df = df[front + rest]\n",
    "df.to_csv(CLEAN_OUT, index=False)\n",
    "print(\"Wrote:\", CLEAN_OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dac4c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: uk_polling_2025_national_dates_for_chart_v2.csv | rows: 240\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "INFILE  = \"uk_polling_2025_national_dates_for_chart.csv\"   # or your v2 file\n",
    "OUTFILE = \"uk_polling_2025_national_dates_for_chart_v2.csv\"\n",
    "\n",
    "df = pd.read_csv(INFILE, dtype=str)\n",
    "\n",
    "party_cols = [\"Lab\",\"Con\",\"Ref\",\"LD\",\"Grn\",\"SNP\",\"PC\",\"Others\"]\n",
    "num_cols = ([c for c in [\"Sample size\"] if c in df.columns] +\n",
    "            [c for c in party_cols if c in df.columns] +\n",
    "            [c for c in [\"Lead\"] if c in df.columns])\n",
    "\n",
    "dash_variants = {\"‚Äì\",\"–\",\"—\",\"−\",\"-\"}\n",
    "\n",
    "def clean_numeric_string(s):\n",
    "    if pd.isna(s): return s\n",
    "    t = str(s).strip()\n",
    "    if t in dash_variants: return \"\"\n",
    "    t = t.replace(\"%\",\"\").replace(\",\",\"\")\n",
    "    if t.lower() == \"tie\": return \"\"\n",
    "    return t\n",
    "\n",
    "# Clean and coerce\n",
    "if \"Sample size\" in df.columns:\n",
    "    df[\"Sample size\"] = pd.to_numeric(df[\"Sample size\"].apply(clean_numeric_string), errors=\"coerce\")\n",
    "for c in [x for x in party_cols if x in df.columns]:\n",
    "    df[c] = pd.to_numeric(df[c].apply(clean_numeric_string), errors=\"coerce\")\n",
    "if \"Lead\" in df.columns:\n",
    "    df[\"Lead\"] = pd.to_numeric(df[\"Lead\"].apply(clean_numeric_string), errors=\"coerce\")\n",
    "\n",
    "# Drop rows where ALL numeric fields are NaN (text/blank artefacts)\n",
    "if num_cols:\n",
    "    df = df[~df[num_cols].isna().all(axis=1)].copy()\n",
    "\n",
    "# Keep date/year tidy if present\n",
    "if \"date\" in df.columns:\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\").dt.date\n",
    "if \"year\" in df.columns:\n",
    "    df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\")\n",
    "\n",
    "df.to_csv(OUTFILE, index=False)\n",
    "print(\"Wrote:\", OUTFILE, \"| rows:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50403dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wm/rntml9cj7270lh5ry0v4gjhc0000gn/T/ipykernel_20785/1746797476.py:55: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(table_html, header=[0, 1])[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote:\n",
      "  - uk_polling_2024_national_dates_for_chart.csv\n",
      "  - uk_polling_2025_national_dates_for_chart.csv\n",
      "  - uk_polling_2024_2025_national_dates_for_chart.csv  (rows=293)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wm/rntml9cj7270lh5ry0v4gjhc0000gn/T/ipykernel_20785/1746797476.py:55: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(table_html, header=[0, 1])[0]\n"
     ]
    }
   ],
   "source": [
    "# uk_polls_2024_2025_extract_and_combine.py\n",
    "# ------------------------------------------------------------\n",
    "# Fetch 2024 + 2025 national polling tables from Wikipedia,\n",
    "# clean them, save per-year CSVs, and a combined CSV.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "WIKI_PAGE = \"Opinion_polling_for_the_next_United_Kingdom_general_election\"\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119 Safari/537.36\"\n",
    "    )\n",
    "}\n",
    "\n",
    "OUT_2024 = Path(\"uk_polling_2024_national_dates_for_chart.csv\")\n",
    "OUT_2025 = Path(\"uk_polling_2025_national_dates_for_chart.csv\")\n",
    "OUT_COMBINED = Path(\"uk_polling_2024_2025_national_dates_for_chart.csv\")\n",
    "\n",
    "# ---------------- utilities ----------------\n",
    "\n",
    "def fetch_wiki_html() -> str:\n",
    "    for url in [\n",
    "        f\"https://en.wikipedia.org/api/rest_v1/page/html/{WIKI_PAGE}\",\n",
    "        f\"https://en.wikipedia.org/w/index.php?title={WIKI_PAGE}&printable=yes\",\n",
    "        f\"https://en.wikipedia.org/wiki/{WIKI_PAGE}\",\n",
    "    ]:\n",
    "        r = requests.get(url, headers=HEADERS, timeout=30)\n",
    "        if r.ok:\n",
    "            return r.text\n",
    "    raise RuntimeError(\"Could not fetch Wikipedia page (all endpoints failed).\")\n",
    "\n",
    "def extract_year_table_html(full_html: str, year: int) -> str:\n",
    "    \"\"\"Find the <h2/3 id='YEAR'> heading, then the first following wikitable.\"\"\"\n",
    "    soup = BeautifulSoup(full_html, \"lxml\")\n",
    "    h = soup.find(lambda t: t.name in (\"h2\", \"h3\") and (t.get(\"id\") == str(year) or t.get_text(strip=True) == str(year)))\n",
    "    if not h:\n",
    "        raise RuntimeError(f\"Heading for {year} not found.\")\n",
    "    nxt = h.find_next()\n",
    "    while nxt and not (nxt.name == \"table\" and \"wikitable\" in (nxt.get(\"class\") or [])):\n",
    "        nxt = nxt.find_next()\n",
    "    if not nxt:\n",
    "        raise RuntimeError(f\"Wikitable for {year} not found.\")\n",
    "    return str(nxt)\n",
    "\n",
    "def table_html_to_df(table_html: str) -> pd.DataFrame:\n",
    "    # Try multi-index header (party colours in second row), then fall back\n",
    "    try:\n",
    "        df = pd.read_html(table_html, header=[0, 1])[0]\n",
    "        df.columns = [c[0] for c in df.columns]\n",
    "    except Exception:\n",
    "        df = pd.read_html(table_html, header=0)[0]\n",
    "\n",
    "    # Remove duplicate header rows that sometimes leak into the body\n",
    "    header_like = tuple(df.columns.tolist())\n",
    "    mask = df.apply(lambda r: tuple(map(str, r.values)) == header_like, axis=1)\n",
    "    df = df.loc[~mask].copy()\n",
    "\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "    wanted = [\"Dates conducted\",\"Pollster\",\"Client\",\"Area\",\"Sample size\",\n",
    "              \"Lab\",\"Con\",\"Ref\",\"LD\",\"Grn\",\"SNP\",\"PC\",\"Others\",\"Lead\"]\n",
    "    ordered = [c for c in wanted if c in df.columns] + [c for c in df.columns if c not in wanted]\n",
    "    return df[ordered]\n",
    "\n",
    "# ------------- cleaning helpers -------------\n",
    "\n",
    "MONTHS = {\"jan\":1,\"feb\":2,\"mar\":3,\"apr\":4,\"may\":5,\"jun\":6,\n",
    "          \"jul\":7,\"aug\":8,\"sep\":9,\"sept\":9,\"oct\":10,\"nov\":11,\"dec\":12}\n",
    "\n",
    "DASHES = {\"‚Äì\",\"–\",\"—\",\"−\",\"-\"}\n",
    "\n",
    "def end_of_fieldwork(s: str, year: int) -> pd.Timestamp:\n",
    "    \"\"\"\n",
    "    Parse 'Dates conducted' to the last day of fieldwork as a Timestamp.\n",
    "    Assumes the table is the given year (works for entries like '26–27 Oct',\n",
    "    '19 Sep – 1 Oct', '8 Oct'). For cross-year spans (e.g., '30 Dec – 3 Jan'),\n",
    "    the end date will be Jan of `year`, which is what we want for charting.\n",
    "    \"\"\"\n",
    "    if pd.isna(s): return pd.NaT\n",
    "    t = str(s).replace(\"\\u2013\",\"-\").replace(\"\\u2014\",\"-\").replace(\"\\xa0\",\" \").strip()\n",
    "    # pick the last 'day month' token\n",
    "    m = re.search(r\"(\\d{1,2})\\s+([A-Za-z]{3,})$\", t)\n",
    "    if not m: return pd.NaT\n",
    "    d, mon = m.groups()\n",
    "    mon = mon.lower()\n",
    "    mon = \"sept\" if mon.startswith(\"sept\") else mon[:3]\n",
    "    try:\n",
    "        return pd.Timestamp(year=year, month=MONTHS[mon], day=int(d))\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "def clean_pollster(s: str) -> str:\n",
    "    if pd.isna(s): return s\n",
    "    # strip all square-bracketed footnotes like [2], [a], etc.\n",
    "    return re.sub(r\"\\s*\\[[^\\]]*\\]\", \"\", str(s)).strip()\n",
    "\n",
    "def clean_numeric_string(s: str) -> str:\n",
    "    if pd.isna(s): return s\n",
    "    t = str(s).strip()\n",
    "    if t in DASHES: return \"\"\n",
    "    t = t.replace(\"%\",\"\").replace(\",\",\"\")\n",
    "    if t.lower() == \"tie\": return \"\"\n",
    "    return t\n",
    "\n",
    "def coerce_numeric_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    party_cols = [\"Lab\",\"Con\",\"Ref\",\"LD\",\"Grn\",\"SNP\",\"PC\",\"Others\"]\n",
    "    if \"Sample size\" in df.columns:\n",
    "        df[\"Sample size\"] = pd.to_numeric(df[\"Sample size\"].apply(clean_numeric_string), errors=\"coerce\")\n",
    "    for c in [x for x in party_cols if x in df.columns]:\n",
    "        df[c] = pd.to_numeric(df[c].apply(clean_numeric_string), errors=\"coerce\")\n",
    "    if \"Lead\" in df.columns:\n",
    "        df[\"Lead\"] = pd.to_numeric(df[\"Lead\"].apply(clean_numeric_string), errors=\"coerce\")\n",
    "    # drop rows where ALL numeric fields are NaN (spurious text/blank rows)\n",
    "    num_cols = ([c for c in [\"Sample size\"] if c in df.columns] +\n",
    "                [c for c in party_cols if c in df.columns] +\n",
    "                [c for c in [\"Lead\"] if c in df.columns])\n",
    "    if num_cols:\n",
    "        df = df[~df[num_cols].isna().all(axis=1)].copy()\n",
    "    return df\n",
    "\n",
    "def add_chart_date(df: pd.DataFrame, year: int) -> pd.DataFrame:\n",
    "    if \"Dates conducted\" not in df.columns:\n",
    "        raise ValueError(\"Expected 'Dates conducted' column.\")\n",
    "    end = df[\"Dates conducted\"].apply(lambda s: end_of_fieldwork(s, year))\n",
    "    df[\"date\"] = end.dt.date\n",
    "    df[\"year\"] = end.dt.year\n",
    "    return df\n",
    "\n",
    "def clean_year_table(html: str, year: int) -> pd.DataFrame:\n",
    "    tbl = extract_year_table_html(html, year)\n",
    "    df = table_html_to_df(tbl)\n",
    "    # pollster footnotes\n",
    "    if \"Pollster\" in df.columns:\n",
    "        df[\"Pollster\"] = df[\"Pollster\"].apply(clean_pollster)\n",
    "    # build chart date + year\n",
    "    df = add_chart_date(df, year)\n",
    "    # numeric coercions + row pruning\n",
    "    df = coerce_numeric_cols(df)\n",
    "\n",
    "    # reorder: put date/year/pollster first\n",
    "    front = [c for c in [\"date\",\"year\",\"Pollster\"] if c in df.columns]\n",
    "    rest = [c for c in df.columns if c not in front]\n",
    "    return df[front + rest]\n",
    "\n",
    "# ------------------ main ---------------------\n",
    "\n",
    "def main():\n",
    "    html = fetch_wiki_html()\n",
    "\n",
    "    df_2024 = clean_year_table(html, 2024)\n",
    "    df_2025 = clean_year_table(html, 2025)\n",
    "\n",
    "    df_2024.to_csv(OUT_2024, index=False)\n",
    "    df_2025.to_csv(OUT_2025, index=False)\n",
    "\n",
    "    combined = pd.concat([df_2024, df_2025], ignore_index=True)\n",
    "    combined = combined.sort_values(\"date\", kind=\"mergesort\").reset_index(drop=True)\n",
    "    combined = combined.drop(columns=[\"year\"], errors=\"ignore\")\n",
    "    combined.to_csv(OUT_COMBINED, index=False)\n",
    "\n",
    "    print(f\"✅ Wrote:\\n  - {OUT_2024}\\n  - {OUT_2025}\\n  - {OUT_COMBINED}  (rows={len(combined)})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26e201a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated uk_polling_2024_2025_national_dates_for_chart.csv\n",
      "Updated uk_polling_2024_national_dates_for_chart.csv\n"
     ]
    }
   ],
   "source": [
    "# pip install pandas\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "COMBINED = Path(\"uk_polling_2024_2025_national_dates_for_chart.csv\")\n",
    "YEAR2024  = Path(\"uk_polling_2024_national_dates_for_chart.csv\")\n",
    "\n",
    "def force_ge_rows_to_election_day(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Make sure date is a datetime (robust to string/object)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "    # Detect the general election result rows\n",
    "    # Wikipedia typically labels these as \"2024 general election\" (may include suffixes, e.g. \"(Survation)\")\n",
    "    has_ge_label = df.get(\"Pollster\", pd.Series([False]*len(df))).astype(str)\\\n",
    "                      .str.contains(\"2024 general election\", case=False, na=False)\n",
    "    # Keep only national coverage rows (GB or UK) when that column exists\n",
    "    if \"Area\" in df.columns:\n",
    "        is_national = df[\"Area\"].astype(str).str.strip().isin([\"GB\",\"UK\"])\n",
    "        mask = has_ge_label & is_national\n",
    "    else:\n",
    "        mask = has_ge_label  # fallback if Area column is missing\n",
    "\n",
    "    # Set the date to the UK general election polling day\n",
    "    election_day = pd.Timestamp(\"2024-07-04\")\n",
    "    df.loc[mask, \"date\"] = election_day\n",
    "    # Keep year consistent too\n",
    "    if \"year\" in df.columns:\n",
    "        df.loc[mask, \"year\"] = 2024\n",
    "\n",
    "    return df\n",
    "\n",
    "# --- Patch combined ---\n",
    "dfc = pd.read_csv(COMBINED, dtype=str)\n",
    "dfc = force_ge_rows_to_election_day(dfc)\n",
    "# Save in ISO (recommended for plotting)\n",
    "dfc[\"date\"] = pd.to_datetime(dfc[\"date\"], errors=\"coerce\").dt.date\n",
    "dfc.to_csv(COMBINED, index=False)\n",
    "print(f\"Updated {COMBINED}\")\n",
    "\n",
    "# --- Patch 2024 file (optional but recommended) ---\n",
    "if YEAR2024.exists():\n",
    "    df24 = pd.read_csv(YEAR2024, dtype=str)\n",
    "    df24 = force_ge_rows_to_election_day(df24)\n",
    "    df24[\"date\"] = pd.to_datetime(df24[\"date\"], errors=\"coerce\").dt.date\n",
    "    df24.to_csv(YEAR2024, index=False)\n",
    "    print(f\"Updated {YEAR2024}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd9791ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: uk_polls_lowess.html\n"
     ]
    }
   ],
   "source": [
    "# Regenerate chart so hover only shows the hovered series (no unified hover).\n",
    "# Change hovermode from 'x unified' to 'closest' and keep all other features from v10.\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "DATAFILE = Path(\"uk_polling_2024_2025_national_dates_for_chart.csv\")\n",
    "OUT_HTML = Path(\"uk_polls_lowess.html\")\n",
    "\n",
    "df = pd.read_csv(DATAFILE, dtype=str)\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "party_cols_all = [\"Lab\",\"Con\",\"Ref\",\"LD\",\"Grn\",\"SNP\",\"PC\",\"Others\"]\n",
    "party_cols = [c for c in party_cols_all if c in df.columns]\n",
    "for c in party_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"date\"]).sort_values(\"date\").copy()\n",
    "\n",
    "# Optional libs\n",
    "have_lowess = False\n",
    "try:\n",
    "    from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "    have_lowess = True\n",
    "except Exception:\n",
    "    have_lowess = False\n",
    "\n",
    "have_kalman = False\n",
    "try:\n",
    "    from statsmodels.tsa.statespace.structural import UnobservedComponents\n",
    "    have_kalman = True\n",
    "except Exception:\n",
    "    have_kalman = False\n",
    "\n",
    "party_colors = {\"Lab\":\"#E4003B\",\"Con\":\"#0087DC\",\"Ref\":\"#12B6CF\",\"LD\":\"#FF6400\",\n",
    "                \"Grn\":\"#02A95B\",\"SNP\":\"#FDF38E\",\"PC\":\"#005B54\",\"Others\":\"#7f7f7f\"}\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "pollster = df.get(\"Pollster\", pd.Series([\"\"]*len(df)))\n",
    "sample   = df.get(\"Sample size\", pd.Series([\"\"]*len(df)))\n",
    "custom_all = np.stack([pollster.fillna(\"\").astype(str),\n",
    "                       sample.fillna(\"\").astype(str)], axis=1)\n",
    "\n",
    "trace_idx = {p: {\"points\": None, \"lowess\": None, \"rolling\": None, \"kalman\": None} for p in party_cols}\n",
    "\n",
    "def prep_daily(series):\n",
    "    s = series.dropna().sort_index()\n",
    "    if s.empty: return None, None\n",
    "    s = s.groupby(level=0).mean()\n",
    "    s = s.asfreq(\"D\").interpolate(\"time\")\n",
    "    return s.index, s.values\n",
    "\n",
    "POINTS_OPACITY = 0.22\n",
    "\n",
    "for party in party_cols:\n",
    "    # points\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df[\"date\"], y=df[party], mode=\"markers\",\n",
    "        name=f\"{party} (points)\",\n",
    "        marker=dict(color=party_colors.get(party), opacity=POINTS_OPACITY, size=6),\n",
    "        customdata=custom_all,\n",
    "        hovertemplate=(\n",
    "            \"%{x|%d %b %Y}<br>\"\n",
    "            + party + \": %{y:.1f}%<br>\"\n",
    "            \"Pollster: %{customdata[0]}<br>\"\n",
    "            \"Sample: %{customdata[1]}<extra></extra>\"\n",
    "        )\n",
    "    ))\n",
    "    trace_idx[party][\"points\"] = len(fig.data)-1\n",
    "\n",
    "    # daily series for smoothing\n",
    "    d = df[[\"date\", party]].dropna().set_index(\"date\")\n",
    "    xs, ys = (None, None)\n",
    "    if len(d) >= 5:\n",
    "        xs, ys = prep_daily(d[party])\n",
    "\n",
    "    # LOWESS\n",
    "    if xs is not None and have_lowess:\n",
    "        xsec = (pd.to_datetime(xs).astype(np.int64) // 10**9).values\n",
    "        sm = lowess(ys, xsec, frac=0.25, it=0, return_sorted=False)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=xs, y=sm, mode=\"lines\", name=f\"{party} (LOWESS)\",\n",
    "            line=dict(color=party_colors.get(party), width=2.7),\n",
    "            hovertemplate=\"%{x|%d %b %Y}<br>\"+party+\": %{y:.1f}%<extra></extra>\",\n",
    "            opacity=1.0\n",
    "        ))\n",
    "        trace_idx[party][\"lowess\"] = len(fig.data)-1\n",
    "\n",
    "    # Rolling\n",
    "    if xs is not None:\n",
    "        ys_roll = pd.Series(ys, index=xs).rolling(window=21, min_periods=5, center=True).mean()\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=ys_roll.index, y=ys_roll.values, mode=\"lines\", name=f\"{party} (21d rolling)\",\n",
    "            line=dict(color=party_colors.get(party), width=2.7, dash=\"dot\"),\n",
    "            hovertemplate=\"%{x|%d %b %Y}<br>\"+party+\": %{y:.1f}%<extra></extra>\",\n",
    "            opacity=0.0\n",
    "        ))\n",
    "        trace_idx[party][\"rolling\"] = len(fig.data)-1\n",
    "\n",
    "    # Kalman\n",
    "    if xs is not None and have_kalman:\n",
    "        mod = UnobservedComponents(ys, level=\"local level\")\n",
    "        res = mod.fit(disp=False)\n",
    "        yk = res.smoothed_state[0]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=xs, y=yk, mode=\"lines\", name=f\"{party} (Kalman)\",\n",
    "            line=dict(color=party_colors.get(party), width=2.7, dash=\"dash\"),\n",
    "            hovertemplate=\"%{x|%d %b %Y}<br>\"+party+\": %{y:.1f}%<extra></extra>\",\n",
    "            opacity=0.0\n",
    "        ))\n",
    "        trace_idx[party][\"kalman\"] = len(fig.data)-1\n",
    "\n",
    "# Masks\n",
    "n = len(fig.data)\n",
    "def vis_mask(selected_parties):\n",
    "    vis = [False]*n\n",
    "    for p in selected_parties:\n",
    "        for key, idx in trace_idx[p].items():\n",
    "            if idx is not None:\n",
    "                vis[idx] = True\n",
    "    return vis\n",
    "\n",
    "all_parties = party_cols\n",
    "top5 = [p for p in [\"Lab\",\"Con\",\"Ref\",\"LD\",\"Grn\"] if p in party_cols]\n",
    "prog = [p for p in [\"Lab\",\"LD\",\"Grn\",\"SNP\",\"PC\"] if p in party_cols]\n",
    "right = [p for p in [\"Con\",\"Ref\"] if p in party_cols]\n",
    "\n",
    "mask_all, mask_top5, mask_prog, mask_right = (\n",
    "    vis_mask(all_parties), vis_mask(top5), vis_mask(prog), vis_mask(right)\n",
    ")\n",
    "\n",
    "def opacity_for_method(method):\n",
    "    op = [None]*n\n",
    "    for p in party_cols:\n",
    "        for meth in [\"lowess\",\"rolling\",\"kalman\"]:\n",
    "            idx = trace_idx[p][meth]\n",
    "            if idx is not None:\n",
    "                op[idx] = 1.0 if meth == method else 0.0\n",
    "    return op\n",
    "\n",
    "op_lowess  = opacity_for_method(\"lowess\")\n",
    "op_rolling = opacity_for_method(\"rolling\")\n",
    "op_kalman  = opacity_for_method(\"kalman\")\n",
    "\n",
    "# Dots toggle arrays\n",
    "def points_opacity_array(value):\n",
    "    arr = [None]*n\n",
    "    for p in party_cols:\n",
    "        idx = trace_idx[p][\"points\"]\n",
    "        if idx is not None:\n",
    "            arr[idx] = value\n",
    "    return arr\n",
    "\n",
    "POINTS_OPACITY = 0.22\n",
    "dots_on  = points_opacity_array(POINTS_OPACITY)\n",
    "dots_off = points_opacity_array(0.0)\n",
    "\n",
    "# Init\n",
    "for i, v in enumerate(mask_all):\n",
    "    fig.data[i].visible = v\n",
    "\n",
    "# Layout: hovermode 'closest' so only hovered series shows\n",
    "start = pd.Timestamp(\"2024-07-04\")\n",
    "end   = df[\"date\"].max() + pd.Timedelta(days=7)\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"UK/GB National Polling — Vote Share\",\n",
    "    xaxis_title=\"Date (end of fieldwork)\",\n",
    "    yaxis_title=\"Vote share (%)\",\n",
    "    hovermode=\"closest\",  # <— key change\n",
    "    hoverlabel=dict(namelength=-1),\n",
    "    template=\"plotly_white\",\n",
    "    legend_title_text=\"Series\",\n",
    "    legend=dict(orientation=\"h\", x=0, y=-0.36, xanchor=\"left\", yanchor=\"top\"),\n",
    "    margin=dict(l=60, r=30, t=60, b=190),\n",
    "    updatemenus=[\n",
    "        # Row 1: Method (line opacity only)\n",
    "        dict(type=\"buttons\", direction=\"right\", x=0, y=-0.10, xanchor=\"left\", yanchor=\"top\",\n",
    "             buttons=[\n",
    "                 dict(label=\"LOWESS\",       method=\"restyle\", args=[{\"opacity\": op_lowess}]),\n",
    "                 dict(label=\"Rolling (21d)\",method=\"restyle\", args=[{\"opacity\": op_rolling}]),\n",
    "                 dict(label=\"Kalman\",       method=\"restyle\", args=[{\"opacity\": op_kalman}]),\n",
    "             ], showactive=False, pad={\"r\":6,\"t\":6}),\n",
    "        # Row 2: Presets (visibility)\n",
    "        dict(type=\"buttons\", direction=\"right\", x=0, y=-0.20, xanchor=\"left\", yanchor=\"top\",\n",
    "             buttons=[\n",
    "                 dict(label=\"All\",        method=\"update\", args=[{\"visible\": mask_all}]),\n",
    "                 dict(label=\"Top 5\",      method=\"update\", args=[{\"visible\": mask_top5}]),\n",
    "                 dict(label=\"Progressive\",method=\"update\", args=[{\"visible\": mask_prog}]),\n",
    "                 dict(label=\"Right\",      method=\"update\", args=[{\"visible\": mask_right}]),\n",
    "             ], showactive=False, pad={\"r\":6,\"t\":6}),\n",
    "        # Single Dots toggle (far right)\n",
    "        dict(type=\"buttons\", direction=\"right\", x=0.88, y=-0.20, xanchor=\"left\", yanchor=\"top\",\n",
    "             buttons=[dict(label=\"Dots On/Off\", method=\"restyle\",\n",
    "                           args=[{\"marker.opacity\": dots_off}], args2=[{\"marker.opacity\": dots_on}])],\n",
    "             showactive=False, pad={\"r\":6,\"t\":6}),\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig.update_xaxes(rangeslider=dict(visible=False), range=[start, end])\n",
    "fig.write_html(str(OUT_HTML), include_plotlyjs=\"cdn\", full_html=True)\n",
    "print(\"Saved:\", OUT_HTML)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc699b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uk-polls)",
   "language": "python",
   "name": "uk-polls"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
